\chapter{Analysis Strategy}%
\label{ch:strategy}

With the objects required for this analysis reconstructed and an event selection
in place an analysis strategy is formed in order to maximise the signal strength
of the \VHbb\ process and yield a robust result that is well understood in terms
of modelling and systematic errors. In this chapter that strategy will be
detailed, first the categorisation into analysis regions will be defined, next
the multi-variate algorithm that is used to generate some of the distributions
entering into the profile-likelihood fit will be explained. Then the fit itself
will be explained, including a definition of the likelihood function and
systematic uncertainty model. Plots of the data versus Monte-Carlo prediction
will then be shown in order to build a picture of the pre-fit status of the
agreement. Finally a series of cross-checks which are used to validate the
methods of the analysis will be explained.

The author's contributions include studying the behaviour of the
profile-likelihood fit with the inclusion of these regions, which are new in
this round of the analysis and making comparisons between the 80~fb$^{-1}$ and
140~fb$^{-1}$ datasets). Contributions also include the training of the
multi-variate classification algorithm with the inclusion of new input variables
with respect to the previous version of the algorithm.

\section{Categorisation Into Analysis Regions}
\label{sec:ana-regions}

Events which pass the selection detailed in table~\ref{tab:event-selection} are
categorised into several regions for analysis. Firstly they are split into what
are known as medium (75 -- 150 \GeV), high (150 -- 250 \GeV) and extreme (>
250 \GeV) $p_T^{V}$. Events are further categorised by jet multiplicity, all
jets are required by the selection to have at least two jets, categories are
defined for events with exactly two, or exactly three jets. In the 2--lepton
channel there is a requirement of three or more jets but when referring to all
three channels at once categorisation is referred to as simply 3--jet or 2--jet.

Furthermore events are categorised into a signal region which is straddled
either side by two control regions. This categorisation is achieved via
continuous cuts defined in the $\Delta R(b, \bar{b})$~--~$p_T^{V}$ plane,
they are chosen to maximise the signal purity in the signal region and are shown
for the 1--lepton channel in figure~\ref{fig:drbb-crs}.
\input{06-analysis-strategy/drbb-cuts}
The regions either side of the signal region are known as the
high-$\Delta R(b, \bar{b})$ and low-$\Delta R(b, \bar{b})$ control regions,
shortened to CRHigh and CRLow respectively.

\subsection{Top \texorpdfstring{$e \mu$}{e mu} Control Region}%
\label{sec:topemucr}

One more region exists only in the 2--lepton channel, it is obtained by
requiring two opposite flavour leptons instead of two same flavour leptons, and
keeping all other selection criteria the same. This region contains almost all
$t\bar{t}$ and single top processes (whose Feynman diagrams belong to the same
sum) matching very closely the number of expected events of each of these
backgrounds in the 2--lepton channel. This region is therefore called the top $e
\mu$ control region. The data from this control region can be used as a
prediction for the number of top process events in the 2--lepton channel once
multiplied by a scale factor which accounts for differences in normalisation.
Since data are used as the prediction for these events modelling of shape or
migration between control regions becomes unnecessary. Given that this region
exists purely to model systematic uncertainties it will explored in more detail
in the subsequent chapter in section~\ref{sec:ttbar_DD}.

\section{Composition of Analysis Regions}
\label{sec:composition}

This section will detail the composition of each analysis region in terms of
background and signal processes. For all regions the signal process is
\VHbb, the prediction for which comes from events generated using \textsc{Powheg
  MiNLO}~+~\textsc{Pythia~8} for quark initiated processes and
\textsc{Powheg}~+~\textsc{Pythia~8} for gluon initiated processes as can be seen
in table~\ref{tab:sigMC}.
\input{06-analysis-strategy/signal-MC}

The 0--lepton channel contains the  $Z\!+\!$jets, $W\!+\!$jets, top quark and
diboson backgrounds. The $Z\!+\!$jets background dominates the mixture in the
2--jet category across signal and control regions. In the 3--jet category the
top-quark processes dominate apart from in CRLow. There is very little signal
contamination in the control regions. As can be seen in table~\ref{tab:bkgMC},
$V\!+\!$jets events are generated using \textsc{Sherpa~2.2.1}, top quark events
are generated using \textsc{Powheg}~+~\textsc{Pythia~8} and diboson events are
generated also using \textsc{Sherpa~2.2.1}, this is true for these backgrounds
across all channels where a Monte-Carlo prediction is used.
\input{06-analysis-strategy/background-MC}

The 1--lepton channel contains the $W\!+\!$jets, $Z\!+\!$jets, top quark, diboson
and multijet backgrounds where multijet is the name given to backgrounds arising
from QCD processes. The channel is dominated by a mixture of $W\!+\!$jets and top
quark processes, CRHigh has a higher purity of top quark processes whereas CRLow
has a high purity of $W\!+\!$jets background. Contribution from multijet and
$Z\!+\!$jets is small across all regions.

The 2--lepton channel contains the $Z\!+\!$jets, top quark and diboson
backgrounds. The $Z\!+\!$jets background dominates across all regions particularly
in both $\Delta R(b, \bar{b})$ control regions. Predictions for the top quark
processes are taken from the top $e \mu$ control region described in
section~\ref{sec:topemucr}. Given that these predictions come from data, the
importance of a good understanding of the remaining large background, $Z$ +
jets, is crucial to the performance of the analysis.

In all channels the diboson background is contained almost entirely within the
signal region.

\section{Multi-variate Event Classification}%
\label{sec:mva}

The signal regions in all channels enter into the profile-likelihood fit as
distributions generated by a multi-variate analysis. The multi-variate algorithm
used to generate this distribution is a BDT trained to separate \VHbb\ from all
other events. Only the signal region enters into the fit as a distribution of
BDT scores, despite this, the BDT itself is trained on the combination of all
$\Delta R(b, \bar{b})$ regions and takes place before the categorisation into
$p_T^V$ bins. All other analysis selection criteria defined in
section~\ref{sec:selection} are applied before training. Training is carried out
separately for each lepton channel and jet multiplicity, a single split at
$150~\GeV$ is used in the 2--lepton channel resulting in eight separate regions
for training as in table~\ref{tab:training-regions}. The impact of the
difference between the fit regions and those that go into training the BDT on
its performance have been studied~\cite{VHMainNote2019}, and in general the
mitigation of over-fitting resulting from having more events to train on
outweighs any change in performance.

\input{06-analysis-strategy/training-regions}
In tests it has been shown that there is significant evidence of
over-training when training is performed on the signal region alone.

The BDT is trained on all of the samples listed in tables~\ref{tab:sigMC}
and~\ref{tab:bkgMC}, this includes the $t\bar{t}$ and single top Monte-Carlo
predictions that are not used in the final fit in the 2--lepton channel as
previously discussed. The inputs are split into two datasets based on whether or
not the event number is even or odd. The model trained on the odd numbered
events is evaluated on the even numbered events and vice versa, this ensures
that training and evaluation take place on statistically independent datasets
but also that as many events are trained on as possible. The final discriminant
is constructed by summing the results from both trainings.

The BDT inputs differ from the final analysis distributions further in that the
$b$-tagging which is applied is not the hybrid tagging discussed in
section~\ref{subsec:hybrid-tagging} but rather just the truth tagging described
in section~\ref{subsec:truth-tagging}. This gives the highest number of events
possible given all of the tagging strategies available and thus gives the most
statistically robust training. The differences between hybrid-tagged and
truth-tagged distributions is small when considering only the sum of all
backgrounds and thus the impact of this decision is small.

It is necessary to deal with distributions that have very long tails so that
cuts are not placed by the BDT in those tails. This is achieved by placing an
artificial limit on the maximum value of each input distribution that
corresponds to leaving 99~\% of signal events in the remaining distribution.
This increases the reproducibility of the training as fewer cuts are wasted by
being placed in long tails.

Table~\ref{tab:MVAinputs} shows the choices of variables used as inputs to the
algorithm in each analysis channel. Inputs are carefully chosen in order to
maximise the performance of the algorithm.
\input{06-analysis-strategy/MVA-inputs}
Table~\ref{tab:BDTSetup} shows the choice of hyper-parameters for the algorithm
as described in terms of \textsc{tmva}~\cite{TMVA} the toolkit for multi-variate
analysis which is built into \textsc{ROOT}~\cite{ROOT}, and was used for
training this algorithm.
\input{06-analysis-strategy/bdt-hps}

Distributions of the inputs to the BDT in 2--jet, high $p_T^V$ region are shown
in
figures~\ref{fig:bdtinputs-0lep},~\ref{fig:bdtinputs-1lep},~\ref{fig:bdtinputs-2lep}
for the 0--, 1-- and 2--lepton channels respectively. In all channels it can be
seen that a high level of separation power in one dimension can be obtained from
the $m(b,\bar{b})$ and $\Delta R (b, \bar{b})$ distributions which are
correlated. In the 0--lepton channel a moderate level of separation can be
obtained from the $\Delta \eta(b, \bar{b})$, $E_T^{miss}$ and $p_T(b_2)$ also.
In the 1--lepton channel $\min(\Delta\phi(\ell,jet))$, $m_{\text{top}}$ and
$p_T(b_2)$ provide the next best one dimensional separation. In the 2--lepton
channel it is the $\cos{\theta(\ell^-,Z)}$, $E_T^{miss}\text{--significance}$,
$\Delta \eta(V, H)$ and $p_T(b_2)$ that provide next best separation.
\input{06-analysis-strategy/2jet-150pTV-input-distributions}

The BDT is designed to maximise the separation between signal and background
Monte-Carlo predictions. This does not take into account the statistical error
on the quantities of each bin in the discriminant distribution. To mitigate this
issue a transformation is applied, details of which are found in
appendix~\ref{app:bdt-transform}. The performance of the algorithm in terms of
over-fitting is found to be robust~\cite{VHMainNote2019} and the separation
between categories can be seen in section~\ref{sec:prefit}.

\section{Profile Likelihood Fit}%
\label{sec:plf}

Ultimately the results of the analysis come from a profile-likelihood fit. This
fit uses a binned likelihood function whose maximum corresponds to the best
agreement between data and the prediction. The likelihood is defined as the
product over all bins of the Poisson probability to observe $N^{\text{obs}}_i$ data
events given a prediction of $N^{\text{pred}}_i(\mu,\bm{k},{\bm\theta})$
events in a given bin $i$,
\begin{equation}
  \mathcal{L}(\mu,{\bm{k},\bm{\theta}}) =
  \prod_{i\in\,\text{bins}} \frac{\left( N_{i}^{\text{pred}}(\mu,{\bm{k,\theta}})
    \right)^{N_{i}^{\text{data}}}}{N_{i}^{\text{data}}\,!}
  \cdot e^{-N_{i}^{\text{pred}}(\mu,{\bm{k,\theta}})}.
  \label{eq:likelihood}
\end{equation}
The number of predicted events $N^{\text{pred}}_i$  is dependent on three sets of
parameters, the signal strength $\mu$, the scale factors $\bm{k}=\left\{k_1,
  ...,k_j\right\}$, and the nuisance parameters  $\bm{\theta} =
\left\{\theta_1,...,\theta_l\right\}$, as follows
\begin{equation}
  N_{i}^{\text{pred}}(\mu,\bm{k},\bm{\theta}) =
  \mu \cdot N_{i,\text{sig}}^{\text{pred}}(\bm{\theta}) +
  \sum_{b\in\,\text{bkg}} k_b\cdot N_{i,b}^{\text{pred}}(\bm{\theta}).
\end{equation}
The ratio between the measured and the expected signal cross-sections
$\mu=\sigma/\sigma_{\text{SM}}$, known as the signal strength, is the parameter
of interest in the nominal fit. It is common to all analysis regions that enter
into the fit. Each of the scale factors $k_j$ and the signal strength scale
either their associated quantity linearly without any prior constraint or
penalty in the likelihood function, in further sections these parameters will be
referred to as floating. Each nuisance parameter $\theta_i$ encodes the
dependence of the prediction on systematic uncertainties into continuous
parameters in the likelihood. Prior knowledge of the uncertainty that these
parameters encode for is expressed as a Gaussian penalty term
$\mathcal{G}(0\,|\,\theta_i,1)$ added to the likelihood for each uncertainty.
The parameters $\theta_i$ are therefore expressed as a number of standard
deviations of a unit Gaussian in the subsequent sections. These penalties
results in a log-normal, or normal dependence of the predicted yields or shapes
on the displayed parameter values.

The nominal fit result in terms of $\mu$ and $\sigma_{\mu}$ is obtained by
maximizing the likelihood function with respect to all parameters.  This is
referred to as the maximized log-likelihood value, MLL. The profile likelihood
ratio test statistic, $q_\mu$, is then constructed as follows:
\begin{equation}
  q_\mu = - 2\; \ln \left[ \mathcal{L} (\mu, \hat{\hat{\mathbf{k}}},
    \hat{\hat{\bm\theta}}_{\mu})\, / \, \mathcal{L} (\hat{\mu},
    \hat{\mathbf{k}}, \hat{\bm\theta}) \right]
\end{equation}
where $\hat{\mu}$ and $\hat{\theta}$ are the parameters that maximise the
likelihood (with the constraint $0 \leq \hat{\mu} \leq \mu$), and
$\hat{\hat{\theta}}_\mu$ are the nuisance parameter values that maximise the
likelihood for a given $\mu$. This test statistic is used to measure the
compatibility of the background only model with the observed data.

% \paragraph{Shape systematic Uncertainties post-processing} 

% In the current systematic model, independent normalization factors are employed
% for the main backgrounds (\ttbar, $\Wboson +$HF and $\Zboson +$HF) independently
% in $2$ and $3(+)$-jet, above or below $$p_T^V$ = 150~\GeV\$. Therefore, the
% extrapolation uncertainty is already accounted for at these boundaries. Most of
% the systematic uncertainties are computed in total $$p_T^V$$ phase space
% ($\geq75~\GeV$) in $2$-jet and $3$-jet events independently to avoid
% double-counting to the best possible. However, migrations at the $pTV=150~\GeV$
% are still possible, and differences in BDTr training and application setup or
% correlations could induce a small uncertainty componant accross jet bins. When
% visible, these effects are reduced with post-processing. The overall component
% of \ttbar ME, ttbar PS and \ttbar, $\Wboson +$HF, $\Zboson +$HF $p_T^V$
% uncertainties in the different jet bins, as well as in the bins
% $75~\GeV<$p_T^V$<150~\GeV$ and $$p_T^V$>150~\GeV$ is removed that way. \\


% Signal \mbb~shape uncertainty follow a similar but more refined treatment. In
% fact, the \VH\ signal is meant to have independent floating parameters in each
% STXS bin. Therefore, \\VH~\mbb uncertainties are treated to have no overall
% impact in each jet and $p_T^V$ analysis bin, and act only as a shape on the
% discriminant, or as an extrapolation between signal and control regions. The
% same approach is adopted for di-boson \mbb uncertainties.

% \subsubsection{Smoothing of the Systematic Uncertainties}
% \label{sec:smooth}
% The uncertainties on reconstructed objects are propagated in the analysis in two
% different ways: by shifting weights, or by modifying the kinematic properties of
% the relevant objects and re-running the analysis chain. For flavour tagging,
% where a scale factor (SF) is used to correct efficiencies in the simulations to
% match those of data, the event weight is varied according to an upward
% (downward) shift of the SF and the change in the final distribution is noted as
% the +1 (-1) $\sigma$ uncertainties. For jet energy scale (JES) uncertainties,
% the jet energies are varied directly. Therefore events can migrate in and out of
% the analysis acceptance. Again the difference in the final discriminant is noted
% as the 1 $\sigma$ error. However, in the case of small variations and/or limited
% available MC statistics, the MC statistical uncertainty can make up a
% substantial part of this supposed systematic difference. Given that independent
% NP are introduce in the analysis to account for the MC statistical
% uncertainties, the inflation of systematic uncertainties due to limited
% statistic should be smoothed out.

% Two so-called ``smoothing'' algorithms are used to mitigate these effects. They
% have been developed for the Run 1 analysis and are based on the merging of
% consecutive bins in MC templates. Systematics templates are built as the ratios
% of varied to nominal MC templates. First, bins from one extremum to the next are
% merged until no local extrema remain in the BDT systematics template for the
% multi-variate analysis, or at most one extremum in the mbb systematics template
% for the cut-based analysis and well as the jet energy resolution systematics in
% the multi-variate analysis. This is an iterative process in which the merging
% performed at each step is chosen as the one for which the difference between
% merged and unmerged templates is smallest. Second, the bins resulting from this
% first algorithm are sequentially merged, starting from the upper end of the
% distribution, until the statistical uncertainty in each of the merged bins,
% calculated in the nominal template, is smaller than 5\%. In each of these merged
% bins, the nominal and systematically shifted contents are compared to give the
% $\pm1\sigma$ variation. This value is then used as the associated uncertainty
% for all the nominal bins in the corresponding merged bin.


% The smoothing procedure is applied to the uncertainties associated to:
% $e\gamma$, MET, muons, taus, jvt, jet, PRW and multi-jet modelling shapes. An
% example of the MET and JES systematics can be found in
% Figure~\ref{fig:Smoothing_Example}. The result of smoothing systematic
% uncertainties is checked to ensure that this is behaving as expected.

% % \begin{figure}[h]
% %   \centering
% %
%   \includegraphics[width=0.65\linewidth]{figures/stat/Smoothing/Region_BMax250_BMin150_Y6051_DSR_T2_L0_distmva_J2_\VHSTXS_SysMET_SoftTrk_ResoPara.png}
% %
%   \includegraphics[width=0.65\linewidth]{figures/stat/Smoothing/Region_BMax250_BMin150_Y6051_DSR_T2_L0_distmBB_J3_\VHSTXS_SysJET_CR_JET_EtaIntercalibration_Modelling.png}
% %      \caption{The variation in 0 lepton channel, 150\,\GeV$< p^{V}_{T}
% <$250\,\GeV region of the MET track-based soft term systematic in the
% multi-variate analysis (top) and the jet energy scale on eta-intercalibration
% systematic in the cut-based analysis (bottom). The dashed lines represent the
% systematic shape before smoothing and the solid lines represent the systematic
% shape after smoothing.}
% % \label{fig:Smoothing_Example}

% % \end{figure}


% \subsubsection{Pruning of the Systematic Uncertainties}
% \label{sec:smooth_prune}

% Several of the uncertainties described in Section~\ref{sec:npdefs} have a
% negligible effect on the distributions entering in the fit.  In addition,
% limited statistics in the MC nominal distributions can produce systematic
% templates with large fluctuations, introducing artificial variations in the fit.
% Therefore, following the Run 1 strategy, uncertainties are removed following a
% ``pruning'' procedure, which is carried out for each category/sub-channel in
% each region.

% Pruning is performed as follows: 
% \begin{itemize}
% \item Neglect the normalization uncertainty for a given sample in a region if either of the
%   following is true:
 
%  \begin{itemize}
%   \item the variation is less than 0.5\%
%   \item both up and down variations have the same sign
    
%  \end{itemize}

% \item Neglect the shape uncertainty for a given sample in a given region if the
%   following is true:
  
%  \begin{itemize}
%   \item not one single bin has a deviation over 0.5\% after the overall
%     normalization is removed
    
%   \item if only the up or the down variation is non-zero and passed the previous
%     pruning steps
    
%  \end{itemize}

% \item An additional pruning is made to remove systematic effects on small
%   samples in all regions. In any given region, that pruning is only applied to
%   samples contributing to less than $1\%$ of the total background and reads as
%   follow:
  
%  \begin{itemize}
%   \item in low sensitivity regions (no bin with $S/B>2\%$), normalization
%     effects below $5$ per mille of the total backgrounds and shapes varying no
%     bin by more than $5$ per mille of the total backgrounds are pruned
    
%   \item in regions where at least one bin has a signal contribution $>2\%$ of
%     the total background, shape and normalization effects are pruned if they
%     generate yield variations in these bins smaller than $2\%$ of the signal
%     yields in these bins
    
%  \end{itemize}
% \end{itemize}

% The list of pruned uncertainties is regularly checked to ensure that this is
% behaving as expected. The value of the threshold is also tested and compared to
% no-threshold for each stable iteration of the fit. This to ensure no
% over-pruning is made and the analysis sensitivity is not artificially
% increased.

\section{Pre-fit Data Versus Prediction}
\label{sec:prefit}

This section shows the pre-fit distributions of the Monte-Carlo prediction
versus the data in every analysis region that enters into the profile-likelihood
fit. Figures~\ref{fig:0lep-2jet-prefit} and \ref{fig:0lep-3jet-prefit} show the
distributions in the 0--lepton channel in the 2--jet and 3--jet regions
respectively. Figures~\ref{fig:1lep-2jet-prefit} and \ref{fig:1lep-3jet-prefit}
show the distributions in the 1--lepton channel in the 2--jet and 3--jet regions
respectively. Figures~\ref{fig:2lep-2jet-prefit} and \ref{fig:2lep-3pjet-prefit}
show the distributions in the 2--lepton channel in the 2--jet and $\geq$3--jet
regions respectively.
\input{06-analysis-strategy/0lep-2jet-prefit}
\input{06-analysis-strategy/0lep-3jet-prefit}
\input{06-analysis-strategy/1lep-2jet-prefit}
\input{06-analysis-strategy/1lep-3jet-prefit}
\input{06-analysis-strategy/2lep-2jet-prefit}
\input{06-analysis-strategy/2lep-3pjet-prefit}
\clearpage
\newpage

\section{Analysis Cross-checks}

The final elements of the analysis strategy are a series of cross-checks that
are designed to ensure the methodology is robust. Firstly there is the di-jet
mass fit, also known as the $m_{bb}$ fit. This cross-check is designed to ensure
that the multi-variate analysis has not introduced any biases that have changed
the result so much that is statistically incompatible with a version of the
analysis that does not use the BDT. This cross-check is performed by simply
taking the $m_{bb}$ distribution in place of the BDT distribution in the
profile-likelihood fit.

The second cross-check is a measurement of the diboson process. Diboson final
states arising from proton-proton collisions are well understood and in this
case are being treated as a standard candle~\footnote{A standard candle is an
  astronomical object with a known absolute luminosity that can be used to aid
  astronomical measurements. }. The rationale here is that if the analysis
methodology produces a measurement of the diboson process that is in agreement
with the Standard Model prediction, and therefore existing measurements, then
the methodology itself has not introduced unexpected effects on the result.
Results of these cross-checks imply both of these tests have been
passed~\cite{VHMainNote2019}.

