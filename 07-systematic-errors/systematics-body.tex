\chapter{Systematic Uncertainties}%
\label{ch:systematics}

So far the only errors considered are the random statistical errors on the data
and Monte-Carlo predictions. Systematic errors enter into the analysis in a
large number of places, in this chapter the systematic errors considered in the
analysis are detailed. In general the systematic errors come in one of two
forms, either a shape effect or a normalisation effect. Normalisation effects
alter the number of events in a given sample across the entire sample simply
changing the total number of events. Shape effects change where events lie in a
given distribution causing events to migrate between bins of a histogram, and
potentially across boundaries that are used to define analysis regions described
in~\ref{sec:ana-regions}.

A sub-category of normalisation effect is the acceptance effect which deals with
the normalisation in a particular region or set of regions. The purpose of the
acceptance uncertainties is to account for any mismodelling in the theoretical
prediction of the quantities used to categorise events into regions be it the
leptonic channel, jet multiplicity or an analysis region. Nuisance parameters in
the profile likelihood fit are used to control the acceptance, they are
implemented as Gaussian probability densities whose priors are estimated in
advance. The priors of all of these so called acceptance uncertainties are
calculated using the double ratio
\begin{equation}
  \left. \dfrac{N_{A}^{\text{nominal}}}{N_{B}^{\text{nominal}}} \middle/ \dfrac{N_{A}^{\text{alternative}}}{N_{B}^{\text{alternative}}} \right.,
  \label{eq:acceptance-dr}
\end{equation}
where the formula has been written agnostic of the specific application so
$N_{A}^{nominal}$ is the number of events in the nominal prediction in some
region or category called $A$ and so on.

Another variant of the normalisation effect are the flavour composition
uncertainties. Rather than impacting the normalisation of an entire background
in terms of how they are categorised in the analysis plots, for example in the
plots in section~\ref{sec:prefit}, they impact the sub-processes split by
flavour of the decay products individually. A heavy flavour process is defined as
one where the two leading jets have flavour (b,~b), (b,~c), (b,~l), or (c,~c),
this categorisation is often written as hf for short for example when
considering all heavy flavour sub-process of the V + jets background one could
write V + hf. Flavour composition uncertainties affect the normalisation of one
of the flavour sub-processes with respect to one of the others, specific details
will follow under the sections relating to the relevant backgrounds.

The rest of this chapter will detail the sources of systematic error broken down
into groups of similar origin. Before breaking down each group of systematic
errors a technique called the Boosted Decision Tree Re-weighting method will be
explained as it used across a number of the different groups. The author's
contributions include the determination of all of the Z + jets systematic
errors, determination of systematic errors relating to the flavour composition
of simulated top process events, and development and testing of the Boosted
Decision Tree Re-weighting method.

\section{Parametrising Variance Due To Shape Uncertainties}
\label{sec:re-weighting}

The predictions entering into the profile-likelihood fit of the analysis can be
written as a probability density $p(\vec{x}|\vec{\theta})$, where $\vec{x} =
[x_{1},..., x_{i}]$ is a vector of observable quantities, with $N$ elements and
$\vec{\theta}$ represents the theoretical parameters of the model. The
parameters may come from the Standard Model theory or phenomenological
considerations that must be taken into account to turn that theory into a usable
prediction.

As described above, shape effects may impact the prediction of a given
Monte-Carlo generator that has a particular set of parameters. The choice of
generator will change the prediction due to different choices made by the
generator creators, including but not limited to, the parton shower model,
hadronisation model and non-perturbative processes. One way to get a handle on
the variance of a particular generator is therefore to literally vary these
choices by picking an alternative generator and drawing a comparison to the
alternative prediction. This method is flawed in ways which will be discussed
but is nonetheless fairly common and often one of the few choices available to
analysers when they are trying to get an idea of what the systematic errors on
the modelling of complex physics processes are. Two such methods of comparison
will be detailed here as they are used in this analysis, they the single
dimension parameterisation described in section~\ref{sec:1D-reweight} and a
multi-dimensional parameterisation described in section~\ref{sec:ND-reweight}.
Following this a hybrid approach which uses both methods will be described in
section~\ref{sec:hybrid-reweight}. These methods are described here in general
and then the specific implementations are discussed later under sections
relevant to the systematic errors they are used to calculate.

\subsection{Single Dimension Parameterisation}
\label{sec:1D-reweight}

The single dimension parameterisation uses the ratio of probability densities
\begin{equation}
  r(\vec{x}) = \frac{p(\vec{x}|\vec{\theta}_{1})}{p(\vec{x}|\vec{\theta}_{0})},
  \label{eq:DensityRatio}
\end{equation}
where the subscripts on $\vec{\theta}$ number different choices of the
parameters which govern the model, for example due to different choice of
generator. Here the subscript 0 denotes the nominal prediction and 1 denotes an
alternative. In order to map the nominal to the alternative it is clear that the
one can multiply $p(\vec{x}|\vec{\theta}_{0})$ by the ratio.

The only way that this calculation is tractable is to consider a single
dimension of the probability density function, specifically a single observable
chosen from the vector $\vec{x}$. The ratio then becomes
\begin{equation}
  r(x_{i}) = \frac{p(x_{i}|\vec{\theta}_{1})}{p(x_{i}|\vec{\theta}_{0})},
  \label{eq:1D-ratio}
\end{equation}
which can in turn be calculated for as many or as few as the elements of
$\vec{x}$ as is desired. It should be noted that when the ratio is calculated
using only a single variable it can still be used to map the $N$ dimensional
nominal prediction to the alternative, however the mapping is only guaranteed to
be successful in the dimension chosen to calculate the ratio and in general
agreement between the two predictions in the other variables can not be relied
upon.

Figure~\ref{fig:IllustKinUncert} shows a graphical illustration of how this
single dimensional ratio is calculated. In practice the ratio is used to derive
a systematic shape uncertainty by weighting each event in the nominal
prediction as a function of the variable $x_{i}$ whose distribution was used to
calculate the ratio. Limitations on the sample size of each prediction mean that
in practice it is better to smooth the ratio via the use of a parametric fit in
order to mitigate any large statistical fluctuations in a single bin of the
ratio (arising from a large fluctuation in one of the predictions in that bin).
In figure~\ref{fig:IllustKinUncert} the parametric fit is represented by the
solid line in the ratio.
\input{07-systematic-errors/re-weighting-illustration}

\subsection{$N$-dimensional Parametrisation}
\label{sec:ND-reweight}

As already alluded to in the previous section there are issues with the
parametrisation in a single dimension. Not only is the mapping only guaranteed
to work in a single dimension but if the technique is applied sequentially on
one variable after another the mapping from the first step can be undone by the
second. That is to say that if one calculates the ratio~\ref{eq:1D-ratio} with
$i=1$ and $i=2$ the re-weighting by $r(x_2)$ will not preserve the agreement
between the two predictions that would be achieved by the re-weighting with
$r(x_1)$. It is clear that this is because a ratio for a given $x_i$ only encode
information relating to the PDFs $p(x_i|\theta_0)$ and $p(x_i|\theta_1)$ whereas
what is wanted is something that encodes the multi-variate distributions
$p(\vec{x}|\theta_0)$ and $p(\vec{x}|\theta_1)$.

A function capable of providing compression of the full multi-variate
distribution has already been discussed, these are the functions that one
obtains when training a machine learning algorithm such as those mentioned
in chapter~\ref{ch:ml}. Functions of the form given in
equation~\ref{eq:ml-general} can encode information from the multi-variate
input $\vec{x}$ into a lower dimensional $\vec{y}$ that captures the
correlations between the different elements of the inputs $\vec{x}$.
Specifically for this parametrisation the model is trained to classify events as
coming from either the Monte-Carlo generator with parameters $\theta_0$ or
$\theta_1$, the output is therefore written as $\vec{y} = [y_0, y_1]$ where each
term in the vector represents the probability that an event comes from
$p(\vec{x} | \theta_0)$ or $p(\vec{x} | \theta_1)$ respectively. Note that the
choice of output function in the model ensure that probability is conserved,
i.e. $y_0 + y_1 = 1$. This technique has been demonstrated in the
literature~\cite{cranmer2016approximating} where the mathematical details are
discussed in more detail.

Our setup allows to create the following approximation
\begin{equation}
  r(\vec{x}) =  \frac{p(\vec{x}|\vec{\theta}_{1})}{p(\vec{x}|\vec{\theta}_{0})}
  \approx \frac{F(\vec{x}, \vec{w})[1]}{F(\vec{x}, \vec{w})[0]},
  \label{eq:bdtr-approximation}
\end{equation}
where $F$ is our trained model whose hyper-parameters we can considered fixed
and drop from the notation (previously denoted $\vec{\theta}$ in
chapter~\ref{ch:ml}). The numbers in the square brackets indicate which element
of the $\vec{y}$ is being selected. Once the above approximation is made the
steps to generate weights and perform a parameterisation of the difference in
shape between two predictions is the same as in the one dimensional case. By
placing certain restrictions on $F$ one can turn the approximation into an
equivalence, this is discussed in~\cite{VHModellingNote2019}, however for what
is considered here the approximation will be the focus.
Figure~\ref{fig:nd-rw-illustration} shows an illustration of the $N$-dimensional
parametrisation procedure. This parametrisation will be referred to in the
analysis as the BDTr method short for BDT re-weighting as the choice of
classifier is a BDT.

\subsection{Hybrid $(N - 1)$--Dimensional Parametrisation}
\label{sec:hybrid-reweight}

It is possible to combine the aforementioned parametrisation strategies into a
single strategy. This is achieved by first re-weighting using the 1--dimensional
technique and then training the classifier on the re-weighted distributions and
proceeding with the $N$--dimensional parametrisation as usual. In principle the
1--dimensional re-weighting can be performed a number of times sequentially
before training the classifier and so therefore a general $(N-k)$--dimensional
strategy can be formed, however in this analysis the 1--dimensional re-weighting
is only applied once before training.

The hybrid approach yields two parametrisations one that parametrising the
difference between the two samples in the single variable used in the
1--dimensional re-weighting and a second that parametrises the remaining
variables using the density ratio formed by using the classifier trained on the
re-weighted distributions. This approach will be referred to as the factorised
BDTr method as the single variable that is not included in the classifier that
is used to generate the multi-dimensional parametrisation is considered to be
factored out.

There are a number of reasons why one might want to factor out a single variable
from the multi-dimensional procedure that naively looks superior in every way to
the 1--dimensional approach. One must considered that when comparing two
Monte-Carlo based generators internal parameters may be used in one of those
generators that are not used in other, this is one reason why a smooth
interpolation between generators may not actually exist. Given that the
parametrisation generated by any of these methods will be input into a
profile-likelihood fit as a Gaussian constrained nuisance parameter that is
varied in a smooth and continuous manner there is therefore incongruity between
the nature of the nuisance parameter and the underlying mapping between
generators. A second nuisance parameter arising from the factorised variable
therefore at least allows the profile-likelihood fit to control more precisely
the histograms relating to that variable. The choice of factorised variable is
also relevant to the choice of using the hybrid method, for example in the fit
the histograms entering in the control regions are of $P_T^V$ and so it may be
sensible to give the fit a parameter to directly control the shape of this
variable.

\section{Experimental Systematic Uncertainties}

This section describes experimental systematic uncertainties, these arise due to
limitations of the hardware discussed in chapter~\ref{ch:detector} and
reconstruction algorithms described in chapter~\ref{ch:recon}. All of these
uncertainties are provided by different combined performance (CP) groups and
made centrally available to members of the ATLAS collaboration, this ensures a
consistent understanding of the performance of the detector and centrally
provided reconstruction algorithms in Athena. A summary of all of the
experimental systematic uncertainties used in the analysis can be found in
table~\ref{tab:expSyst}.
\input{07-systematic-errors/experimental-table.tex}

\subsection{Luminosity and Pile-up}
\label{sec:lumisys}

As discussed in chapter~\ref{ch:detector} luminosity is used to measure how much
data is recorded by the detector in any span of time. The uncertainty is
calculated for each year of running and is determined to be  2.1\%, 2.6\%,
2.4\%, and 2.0\% for the years 2015, 2016, 2017, 2018 respectively. A combined
uncertainty is calculated for the entire period 2015--2018 at 1.7\%. The
methodology used to calculate this figure is similar to that detailed
in~\cite{lumiDetermine}, from calibrations of the luminosity scale using x--y
beam-separation scans~\cite{lumiTwiki}.

Pile-up uncertainties are computed by changing the nominal data scale of
$1.0/1.03$ to $1.0/1.00$ and $1.0/1.18$ to get the up and down variations
respectively~\cite{puTWiki}.

\subsection{Triggers}
\label{sec:trigsys}

\subsubsection{\texorpdfstring{$E_T^{\text{miss}}$}{MET} Triggers}

Scale factors are derived for the $E_T^{\text{miss}}$ triggers using
$W(\mu,\nu)$ + jets events as outlined in~\cite{VHObjectNote2019}.

Three uncertainties are taken into account, the statistical error on the dataset
used to derived the scale factor \texttt{METTrigStat}, a parameter used to
account for the choice of physics process and the effect that might have on the
determination of the scale factor \texttt{METTrigTop} and \texttt{METTrigSumPt}
which aims to account for dependence of the offline $S_T$ (as defined
in~\ref{sec:0lep-selection}) on the trigger efficiency. The uncertainty
\texttt{METTrigTop} is named as such because it is derived from a comparison of
the scale factors as calculated with a $t\bar{t}$ sample and compared to the
nominal sample. The uncertainty relating to $S_T$ is only applied to events
recorded in 2017 due to a specific trigger used in this year.

\subsubsection{Lepton trigger}

The CP group recommendations for the lepton triggers can be found
in~\cite{VHObjectNote2019}. The group provide a tool for determining the lepton
trigger systematic error which is implemented in the CxAOD Framework (mentioned
in section~\ref{sec:cxaod}). The nuisance parameter
\texttt{EL\_EFF\_Trigger\_Total\_1NPCOR\_PLUS\_UNCOR} is used to control the overall
uncertainty on the electron trigger. For the muons, the tool returns two components
\texttt{MUON\_EFF\_TrigSystUncertainty} and \texttt{MUON\_EFF\_TrigStatUncertainty}
which account for the systematic error and the statistical error on scale factor
respectively. An up and down variation of 1-$\sigma$ are used for all of the
aforementioned nuisance parameters.

\subsection{Electrons}

\subsubsection{Electron Efficiency Uncertainties}

The efficiency of the electron reconstruction and identification (discussed
in~\ref{subsec:electrons}) has a systematic uncertainty provided by the relevant
CP group called \texttt{ElectronEfficiencyCorrection}~\cite{electronTWiki}.
These have been calculated using the full run 2 data. Reconstruction is 97-99\%
efficient across the full $p_T$~spectrum. Identification has an efficiency scale
factor is available from $p_T>7$~\GeV. An isolation efficiency scale factor is
also included. The latest uncertainties that are available include scale factors
for $p_T>150$~\GeV\ that are unity due to the available sample being to small in
statistics to measure a scale factor~\footnote{Check if this is for all electron
  systs}. An additional systematic uncertainty of $\pm 2\%$ is assigned above
150~\GeV\ to over this shortcoming. The above uncertainties are controlled by
\texttt{EL\_EFF\_ID\_Total\_1NPCOR\_PLUS\_UNCOR},
\texttt{EL\_EFF\_Reco\_Total\_1NPCOR\_PLUS\_UNCOR}, and
\texttt{EL\_EFF\_Iso\_Total\_1NPCOR\_PLUS\_UNCOR} in the profile-likelihood fit.

\subsubsection{Electron Energy Scale and Resolution Uncertainties}

Energy scale and resolution systematic uncertainties have been provided by the
relevant CP group~\cite{EgammaCalibTWiki}. Whilst there are a large number of
uncertainties provided by the group, this analysis is not very sensitive to the
energy scale or resolution of electrons and therefore only two uncertainties are
considered which are called \texttt{EG\_RESOLUTION\_ALL} and
\texttt{EG\_SCALE\_ALL}.

\subsection{Muons}

\subsubsection{Muon Efficiency Systematic Uncertainties}

Samples of $Z \to \mu\mu$ and $J/\psi \to \mu\mu$ events from the full 2015
dataset (corresponding to 3.2~\invfb) are used to calculate scale factors to
account for uncertainties in the reconstruction, isolation and track-to-vertex
association~\cite{muonTWiki}. These scale factors are valid in the full $p_T$
spectrum with the $J/psi$ measurement providing more accurate determination in
the $p_T$<15~\GeV\ region and the Z measurement being more accurate in the
$p_T$>15~\GeV\ region. Four independent systematic uncertainties are considered
which are called \texttt{MUON\_EFF\_RECO\_STAT},

\texttt{MUON\_EFF\_RECO\_STAT\_LOWPT}, \texttt{MUON\_EFF\_RECO\_SYS},
\texttt{MUON\_EFF\_RECO\_SYS\_LOWPT}, which are split based on whether or not
they come from the high or low $p_T$ measurement. Statistical and systematic
uncertainties to the isolation scale factor are controlled by
\texttt{MUON\_EFF\_ISO\_STAT} and \texttt{MUON\_EFF\_ISO\_SYS} respectively.
They are supported in the range of $10 < p_T < 500$~\GeV. For muons outside of
this range, a scale factor of 1$\pm$0.05 is used.
\texttt{MUON\_EFF\_TTVA\_STAT} and \texttt{MUON\_EFF\_TTVA\_SYS} control the
systematic uncertainty on the scale factor of the cuts on the impact parameter
significance and the $|z_0\sin\theta|$ which estimate the error on
track-to-vertex association. All of the above systematic uncertainties are
derived using $\pm 1\sigma$ variations in the relevant samples.

\subsubsection{Muon Momentum Scale and Resolution Uncertainties}

Similarly to the electron energy scale and resolution uncertainties described
above the muon momentum scale and resolution uncertainties are provided by the
relevant CP group~\cite{muonTWiki}. Measurements of muons have been calibrated
using a sample of  $Z\rightarrow \mu\mu$ events in the region with
$p_T$~>~20~\GeV\ and with a sample of $J/\psi\rightarrow \mu\mu$ events in region
with $p_T$~<~20~\GeV. The nuisance parameters control the uncertainties due to
the inner detector, muon system and the overall momentum scale, they are called
\texttt{MUONS\_ID}, \texttt{MUONS\_MS} and \texttt{MUONS\_SCALE} respectively.
These systematic uncertainties are derived by varying the momentum scale and the
track position in the detector by $\pm 1\sigma$. Two parameters which account
for the charge dependence of the of the momentum scale uncertainty
\texttt{MUON\_SAGITTA\_RHO} and \texttt{MUON\_SAGITTA\_RESBIAS} are also included.

\subsection{Taus}

Taus are not crucial to the analysis and therefore the systematic uncertainties
on the measurement of taus does not have a large effect on the result. The
systematic uncertainties considered in the analysis relating to taus are
\texttt{TAUS\_TRUEHADTAU\_SME\_TES\_DETECTOR},
\texttt{TAUS\_TRUEHADTAU\_SME\_TES\_INSITU} and
\texttt{TAUS\_TRUEHADTAU\_SME\_TES\_MODEL}, which all account for different
sources of energy scale uncertainty.

\subsection{Jets}

As with the other reconstructed objects discussed so far the systematic
uncertainties for jets are provided through a central tool written by the
relevant CP group that is interfaced in the CxAOD Framework. Analyses may choose
between a number of different schemes, the choice for the VH(bb) analysis is to
use a reduced set of 23 nuisance parameters comi
ng from a reduction using
principal component analysis of the baseline set of parameters. The baseline set
accounts for effects due to eta calibration, high-$p_T$ jets, pile-up, flavour
composition, flavour response, $b$-jets, and punch-through jets. The 23 nuisance
parameters and a short description of each are displayed in
table~\ref{tab:expSyst} under the category jets and $b$-tagging where all of the
relevant nuisance parameters start with \texttt{JET} and
\texttt{JET\_CR\_Flavour\_Composition} represents three independent nuisance
parameters as explained in its short description.

The largest source of uncertainty amongst the chosen set come from the jet
energy scale and the jet energy resolution. The determination of the former is
documented in~\cite{JetCalibration2015} and the latter is determined from data
versus Monte-Carlo prediction comparisons.

\subsection{$E_T^{\text{miss}}$}

Once again $E_T^{\text{miss}}$ systematic uncertainties are implemented via a
centrally available tool written by the relevant CP group and interfaced in the
CxAOD Framework. The tool is configured to account for calorimeter and track
based jets, the uncertainties considered in this analysis are under the heading
$E_T^{\text{miss}}$ in table~\ref{tab:expSyst} and start with \texttt{MET}.

\subsection{Flavour Tagging}

The uncertainties relating to the flavour tagging procedure detailed
in~\ref{sec:btagging} are very important to consider in the analysis as the
tagging itself has a central role in selecting events in all of the leptonic
channels. Each event that has been passed through the tagging algorithms has
event weights that encode the systematic error on the tagging. The following
describes how these scale factors are calculated with reference to the tool
provided by the relevant CP group. For each signal events apply the scale factor
from the CP tool if it has been tagged as a $b$-jet, otherwise apply the
inefficiency scale factor provided by the same tool (which yields the nominal
event weight). For each of the systematic uncertainties considered vary the
scale factor and inefficiency scale factor by the variations provided by the CP
tool and repeat the previous method (note the varied inefficiency scale factor
will no longer yield the nominal event weight). For all histograms that would
enter the profile-likelihood fit a separate histogram is created for each
systematic uncertainty (both an up and down variation where the uncertainties
are two-sided).

Similarly to in the determination of the systematic uncertainties on the jets, a
large number of individual systematics are available (about 40 per jet flavour)
and so in order to have a smaller set to work with a principle component
analysis of the full set is performed by the CP group. For the working point
(70~\%) and reduction scheme chosen in this analysis there are 3 variations for
$b$-jets, 3 variations for $c$-jets and 5 variations for light-jets. These are
named \texttt{FT\_EFF\_Eigen\_Light0}, \texttt{FT\_EFF\_Eigen\_Light1},
\texttt{FT\_EFF\_Eigen\_Light2}, \texttt{FT\_EFF\_Eigen\_Light3},\\
\texttt{FT\_EFF\_Eigen\_Light4}, \texttt{FT\_EFF\_Eigen\_B0},
\texttt{FT\_EFF\_Eigen\_B1}, \texttt{FT\_EFF\_Eigen\_B2},
\texttt{FT\_EFF\_Eigen\_C0}, \texttt{FT\_EFF\_Eigen\_C1} and
\texttt{FT\_EFF\_Eigen\_C2}.

Two additional systematic uncertainties irrespective of reduction scheme are
considered that relate to the $p_T$ extrapolation~\cite{BTaggingExtrap2015} and
charm-to-bottom quark extrapolation, they are called
\texttt{FT\_EFF\_Eigen\_extrapolation}, and
\texttt{FT\_EFF\_Eigen\_extrapolation\_from\_charm} respectively.

\section{V + jets Systematic Uncertainties}
\label{sec:vjets}
Whilst the physics of the W and Z + jets processes leads to them being in
different channels and needing to be treated differently in the analysis, the
underlying theory means that simulation of these processes is coupled,
particularly as they are simulated with the same software.

The V + jets processes are simulated with
\textsc{Sherpa}~2.2.1~\cite{1126-6708-2009-02-007} as mentioned in
section~\ref{sec:composition}, which is interfaced with the
NNPDFs~\cite{Ball:2012cx} for both the matrix element calculation and the parton shower
tuning. Events with many additional jets produced in association with the vector
boson largely contribute to the background in this analysis, therefore a feature
of \textsc{Sherpa}~2.2.1 is used in which it provides a combination of matrix
elements with different parton multiplicities. Up to 2 extra partons are
included in the next-to-leading order matrix element, and 3 or 4 extra partons
are included at leading order in QCD. In order to combine different patron
multiplicities a matching scheme based on the CKKW-L~\cite{Lonnblad:2001iq,
  Lavesson:2005xu} merging technique is used, with a merging scale of $Q_{cut} =
20$~\GeV. Simulation of events with more than 4 extra partons relies on the
parton shower algorithm of \textsc{Sherpa}. The parton shower and underlying
events models are included in \textsc{Sherpa} whose generator adopts a full
5--flavour scheme with b- and c-quarks being treated as massless in the matrix
element, in the version used. Massive quarks can be produced in the parton
shower and heavy flavours (quarks as heavy or heavier than a c-quark) can be
produced directly in the scattering process of the underlying event.

The analysis gains a lot of sensitivity from high $p_T^V$ regions of phase
space, and also has the requirement of two b-tagged jets in the event selection
as mentioned in section~\ref{sec:selection}. It is therefore important to ensure
that a large statistical sample in these regions is available such that
fluctuations are smaller than those that would be found in the data. In order to
achieve this two methods are used, firstly samples are simulated in specific
slices of the larger of the $p_T$ of the vector boson or the $H_T$ of the event.
Events are simulated in the following slices
\begin{equation}
  \text{max}(p_T^V, H_T) = [0\text{--}70, 70\text{--}140, 140\text{--}280, 280\text{--}500, 500\text{--}1000, >1000]~\GeV.
\end{equation}
The dedicated slices at high $\text{max}(p_T^V, H_T)$ ensure a large number of
events are simulated in the high $p_T^V$ region of phase space. Secondly filters
are applied on the flavour of the jets that produced in association with the
vector boson.  The filters used for these samples are shown in
table~\ref{tab:bc-filters}.
\input{07-systematic-errors/bc-filters}
The filters are not applied to the highest slices in $\text{max}(p_T^V, H_T)$.
The filtering strategy for $Z\nu\nu$ samples differs in the mc16e campaign using
a combination of $p_T^Z$ and $m_{jj}$ to better populate the region above the
MET trigger thresholds, and VBF phase spaces with high $m_{jj}$. These samples
also use a tighter b-filter compared to their mc16a/d counterpart which is also
described in table~\ref{tab:bc-filters}. All nominal V + jets samples with the
corresponding max($H_T$,$p_T^V$) slices and flavour filters are listed in
tables~\ref{tabular:mc_samples_Wjets} \ref{tabular:mc_samples_Zlljets}, and
\ref{tabular:mc_samples_Zvvjets} in the appendices.
+
A set of alternative predictions are used for a number of purposes in the
analysis, one such purpose is to investigate any discrepancies that may arise
between data and the nominal prediction. If the same discrepancy is present when
comparing he alternative prediction to data then the discrepancy may arise from
experimental error rather than weaknesses in the modelling. One kind of
modelling uncertainty also relies on the comparison of two predictions, for
example the nominal versus the alternative.

The alternative samples are generated using
\textsc{MadGraph}~5~\cite{MADGRAPH5_aMC@NLO} interfaced to \textsc{Pythia}~8 for
the modelling of the parton shower and the underlying event. The
\textsc{MadGraph}~5 v2 generator provides a LO (QCD) description of these
processes, merging together matrix-element calculations with different parton
multiplicities, up to 4 additional jets, higher jet multiplicities are modelled
by the parton shower algorithm. The merging scheme applied to combine different
parton multiplicities is the same as for the nominal samples, the CKKW-L scheme,
but has a merging scale of $Q_{cut} = 30$~\GeV. For the LO ME calculation the
NNPDF2.3 LO PDFs are used, with $\alpha_S = 1.3$.  Similarly to
\textsc{Sherpa}~2.2.1, also \textsc{MadGraph}~adopts a full 5-flavour scheme
with massless quarks in the ME calculation, while massive quarks can be produced
by the parton shower. All alternative V + jets samples are listed in
tables~\ref{tabular:zjetsAlternativeSamples} and
\ref{tabular:wjetsAlternativeSamples} in the appendices.

As well as using an alternative Monte-Carlo generator the nominal generator,
\textsc{Sherpa}, includes systematic variations internally. Every
\textsc{Sherpa}~2.2.1 V + jets sample has an event weight corresponding to each
of the variations detailed in table~\ref{tab:sherpa-variations}\footnote{Some of
the variations cannot be produced by \textsc{Sherpa}~2.2.1 and so
\textsc{Sherpa}~2.1 is used instead. For these variations half of the variation
in each direction is taken as the uncertainty rather than comparing to the
central value of the \textsc{Sherpa}~2.2.1 prediction.}.
\input{07-systematic-errors/vjets-sherpa-vars.tex}

\subsubsection{V + jets Cross Section}
The V + jets cross sections are known at NNLO (QCD)~\cite{Butterworth:1287902},
the higher order cross sections are used to normalise the V+jets samples in the
analysis. For the W + jets samples the total cross section from \textsc{Sherpa} or
from \textsc{MadGraph}, averaged across all 3 lepton flavours taking into account the
different hadron filter efficiencies, is scaled to the NNLO prediction obtaining
scaling factor of $k_{\text{NNLO}}^{\text{QCD}} = 0.9702$.

For Z + jets some subtleties must be considered. For $Z \to \ell\ell$ + jets the
cut at generator level, $m_{\ell\ell}>40$ \GeV, must be taken into account. The
NNLO calculation uses a cut of $66<m_{\ell\ell}<116$ \GeV, which can be applied
at truth level to the samples of this analysis in order to get the scaling
correct as follows:
\begin{equation}
  k_{\text{NNLO}}^{\text{QCD}} = \frac{\sigma_{\text{NNLO}}(66<m_{\ell\ell}<116\,{\GeV})}{\sigma_{\textsc{Sherpa},\textsc{MadGraph}}(66<m_{\ell\ell}<116\,{\GeV})},
  \label{eq:nnlo-vjets-k}
\end{equation}
hence the scaling factor is found to be $0.9751$. For $Z \to \nu\nu$ +jets the
NNLO no theoretical cross section is available. Values from the
Particle Data Group (PDG)~\cite{PDG} are used to correct for the difference
between the BR($Z \to \nu\nu$) and BR($Z \to \ell\ell$), and the NNLO cross
section is used without any mass cuts and with the $Z/\gamma^*$ interference
removed. The scaling factor is therefore calculated to be $0.9728$. It is not
necessarily expected that the scaling factors should be different for $Z \to
\ell \ell$ and $Z \to \nu \nu$ events but this can be explained as both
\textsc{Sherpa} and \textsc{MadGraph} used different branching ratios for these
two processes in their generators compared with those used by the higher order
theoretical calculations.

\subsection{W + jets Modelling Uncertainties}
A number of nuisance parameters are introduced to account for modelling
uncertainties on the W + jets background process. These uncertainties are
considered and derived in the 0-- and 1-- lepton channels only as the amount of
W + jets background present in the 2--lepton channel is negligible. A summary of
all of the uncertainties for this background can be found in
table~\ref{tab:wjets_systematics}.

The nominal and alternative predictions described in~\ref{sec:vjets} are used to
in the determination of all of the values described in the following. 

\subsubsection{Normalisation and Acceptance Uncertainties}

A summary of the normalisation uncertainties is shown in
table~\ref{tab:wjetsnorm}.
\input{07-systematic-errors/wjets-norm-table}
A single nuisance parameter is introduced for each of the W + cl and W + l
processes which are both heavily suppressed by the analysis requirement of two
b-tagged jets. There is a large mismodelling of the normalisation of the W + hf
process and so floating normalisations are used separately in the 2--jet and
3--jet categories. Priors for several acceptance uncertainties are calculated using
equation~\ref{eq:acceptance-dr}\footnote{Whilst the priors are obtained with the
  double ratio formula involving two regions, the effect of the uncertainty is
  applied to only one of the two regions. This does not affect the result but
  only the interpretation of the resulting acceptance factor.} which are used to
control the migration of events between the 0-- and 1--lepton channels and the
migration between the $\Delta R(b, \bar{b})$ regions.

The parameter controlling migration between the two leptonic channels
\texttt{SysWbbNorm\_L0} is applied to both the 2--jet and 3--jet regions of the
0--lepton channel. The choice to apply to the 0--lepton channel and not the
1--lepton channel is made because the 1--lepton channel provides a better
constraint on the W + hf process. Whilst all alternative predictions are
considered the size of this prior is dominated by the difference between the
nominal prediction and \textsc{MadGraph}.

Migration between the $\Delta R(b, \bar{b})$ control regions and the signal
region is controlled by one parameter per control region. Named
\texttt{SysWbbCRSRextrap} it can be seen in table~\ref{tab:wjetsnorm} that it is
applied in each of the control regions, it is also correlated across jet
multiplicity and leptonic channel. The shape uncertainty which uses the BDTr
method discussed in section~\ref{sec:ND-reweight} induces migration effects
across the analysis regions, however in order to increase the degrees of freedom
available to the profile-likelihood fit that systematic is taken as a shape only
effect. The migrations induced by the shape uncertainty agree well with those
derived from comparisons between nominal and alternative predictions, and the
sign of the final priors is determined by migration due to the shape
uncertainty. The magnitude of the prior is calculated as the quadrature sum of
the difference between the nominal prediction and \textsc{MadGraph} as well as
the scale and parton density function variations included in \textsc{Sherpa}.
There is no dedicated nuisance parameter to control the migration between the
$p_T^V$ regions of the analysis as this migration is controlled by the $p_T^V$
shape uncertainty.

\subsubsection{Flavour Composition Uncertainties}

As introduced at the start of this chapter the W + jets background has a W + hf
component that is comprised of the $bb$, $bc$, $bl$ and $cc$ sub-components. The
fractional contribution of each of these sub-components is detailed in
table~\ref{tab:whf-comp}.
\input{07-systematic-errors/whf-components}
Flavour composition uncertainties are computed using
equation~\ref{eq:acceptance-dr} for each sub-component, the calculated priors
are summarised in tables~\ref{tab:wjets-flavour-comp} separately in the 0-- and
1--lepton channels~\footnote{Whilst these numbers were calculated using the
  categorisation and samples of this analysis, due to incomplete availability of
  \textsc{Sherpa} internal variations a set of numbers calculated in a previous
  iteration of the analysis are displayed and used.}.
\input{07-systematic-errors/wjets-flavour-comp}
The flavour composition uncertainties are dominated by the difference between
\textsc{Sherpa} and \textsc{MadGraph}. Individual uncertainties for different
jet multiplicities or analysis regions are not considered necessary due to a
small amount of non-$bb$ events remaining after the 2 b-tag requirement is
imposed.

\subsubsection{Shape Uncertainties}

The hybrid $(N-1)$--dimensional parametrisation technique described
in~\ref{sec:hybrid-reweight} is used to generate uncertainties on the shape of
the distributions of the W + jets background. The variable that has been
factorised out is $p_T^V$ and so there are nuisance parameters which control the
$p_T^V$ shape in each of the 2-- and 3--jet categories as well as a nuisance
parameter that controls the multi-variate shape uncertainty across all regions
and jet multiplicities. These nuisance parameters are summarised in
table~\ref{tab:wjets-shapes}.
\input{07-systematic-errors/wjets-shapes-table}

Shapes are derived in regions split by leptonic channel and heavy flavour
sub-component, yielding eight regions total. The W + l and W + cl components of
the W + jets backgrounds are not considered as they account for less than 1~\%
of all background events in any region.

In all regions the initial 1--dimensional re-weighting is performed by comparing
the ratio of the nominal \textsc{Sherpa}~2.2.1 $(p_T^V, E_T^{\text{miss}})$
prediction with that of \textsc{MadGraph}. The requirement of $p_T^V~>~75$~\GeV\
is applied to all distributions in the 1--lepton channel and in the 0--lepton
channel the requirement of $E_T^{\text{miss}}~>~150$~\GeV\~is imposed instead.

Figures~\ref{fig:wjets_1lep_2jet_SysWPtVBDTr}
and~\ref{fig:wjets_1lep_3jet_SysWPtVBDTr} show the comparison between
\textsc{Sherpa} and \textsc{MadGraph} in the  $p_T^V$ variable in the 2-- and
3--jet categories, respectively. 
\input{07-systematic-errors/wjets-1lep-ptv-shapes}
The systematic uncertainties on the shape are shown in the ratio panel at the
bottom of each plot in green.

The low number of events available in the 0--lepton channel mean that it is not
statistically viable to generate a parametrisation in that channel, therefore
the shapes derived in the 1--lepton channel are also used in the 0--lepton
channel. Figure~\ref{fig:wjets_01lep_2jet_SysWPtVBDTr}
and~\ref{fig:wjets_01lep_3jet_SysWPtVBDTr} show a comparison of the $p_T^V$
shapes derived in the 1--lepton channel compared with the equivalent systematic
derived in the 0--lepton channel in the $E_T^{\text{miss}}$ variable for the 2--
and 3--jet categories, respectively.
\input{07-systematic-errors/wjets-01lep-ptv-shapes}
It can be seen the two shapes mostly agree within the statistical error which is
of course very large for the 0--lepton systematic. Furthermore
figure~\ref{fig:wjets_01lep_2jet_bl_SysWPtVBDTr_From150} shows  a comparison in
which both the $p_T^V$ and the $E_T^{\text{miss}}$ shapes in the 2--jet region
have been normalised to unit area in the $(p_T^V, E_T^{\text{miss}}) > 150$~\GeV\
range where it can be seen that agreement is event better further supporting the
validity of this choice.
\input{07-systematic-errors/wjets-01lep-ptv-shapes-norm}

As per the methodology of the factorised BDTr technique the nominal
\textsc{Sherpa}~2.2.1 events are re-weighted by the $p_T^V$ ratio with the
alternative prediction as was just discussed. The $p_T^V$ shape uncertainty is
therefore factorised out of the BDTr shape uncertainty. The re-weighted
\textsc{Sherpa}~2.2.1 events are then trained against the \textsc{MadGraph}
prediction in a BDT classifier that uses the input variables detailed in
table~\ref{tab:MVAinputs}. A separate training is performed in each jet category
and for each sub-component of the W + hf process in congruence with the 8
regions that the $p_T^V$ shape was derived in. Considering the output of the
classifier the ratio of the scores of the nominal and alternative predictions
enter into the profile-likelihood fit as a nuisance parameter called
\texttt{SysBDTr\_W\_SHtoMG5}. All of the following plots shown contain only W +
bb events as this is the dominant and most important component of the W + hf
process and indeed the W + jets background in the analysis.

In order to check the validity of the method the re-weighted nominal predictions
of key inputs to the analyisis MVA are plotted against the nominal and
alternative predictions in figures~\ref{fig:wjets_1lep_2jet_BDTrClosure_1}
and~\ref{fig:wjets_0lep_2jet_BDTrClosure_1} for the 1-- and 0--lepton channels
respectively in the 2--jet category.
\input{07-systematic-errors/wjets-bdt-shapes-1lep2jet}
\input{07-systematic-errors/wjets-bdt-shapes-0lep2jet}
Should the re-weighted nominal inputs match
the shapes of the alternative inputs then the method is considered to be valid.
Indeed upon inspection one can see that this is largely the case across the
board apart from small levels of disagreement. These small levels of
disagreement are disregarded as the two most important variables in the
determination of the analysis BDT score, $m(b, \bar{b})$, $p_T^V$ and
$E_T^{\text{miss}}$ have good levels of agreement.

The actual effect of the factorised BDTr systematic uncertainty on the analysis
BDT score is shown in figures~\ref{fig:wjets_1lep_FullRun2MVA_BDTrClosure}
and~\ref{fig:wjets_0lep_FullRun2MVA_BDTrClosure} for the 1-- and 0--lepton
channels respectively. 
\input{07-systematic-errors/wjets-bdt-shapes-mva-1lep}
\input{07-systematic-errors/wjets-bdt-shapes-mva-0lep}
Tables~\ref{tab:wjets-extrapolation_uncertainties_pTV}
and~\ref{tab:wjets-extrapolation_uncertainties_BDTr} in the appendix show the
extrapolation uncertainties induced by the $p_T^V$ and factorised BDTr shape
systematic uncertainties respectively.

\subsection{Z + jets Systematic Errors}
\label{sec:zjets-systs}

Systematic uncertainties are considered in the 0-- and 2--lepton channels only
as there is a negligible contribution of this background in the 1--lepton channel.

\subsubsection{Normalisation and Acceptance Uncertainties}

Several normalisation and acceptance uncertainties are considered for the Z +
jets background, they are summarised in table~\ref{tab:zjetsnorm}.
\input{07-systematic-errors/zjets-norm-table}
One nuisance parameter is used for each of the Z + l and Z + cl components as
they are sub-dominant accounting for less than 1~\% of the total background in
any region due to the requirement of two b-tags, they are called
\texttt{SysZlNorm} and \texttt{SysZclNorm} respectively. These normalisations
are each correlated across all regions.

The Z + hf process has a large normalisation uncertainty and so therefore the
decision is made to have separate nuisance parameters for the 2--jet and 3--jet
regions, these are called \texttt{norm\_Zbb\_J2} and \texttt{norm\_Zbb\_J3}
respectively. These parameters are heavily constrained in the fit due to a very
large number of Z + jets events in the 0-- and 2--lepton signal regions and due
to high Z + jets purity particularly in the 2--lepton control regions.

Nuisance parameters are introduced to the model migration of events between
regions. The priors for these parameters are calculated using the double ratio
in equation~\ref{eq:acceptance-dr}. Firstly a parameter is introduced in order
to account for the difference in the number of Z + jets in the 0-- and 2--lepton
channels, is it called \texttt{SysZbbNorm\_0L} and is applied to Z + hf events
in the 0--lepton channel as the 2--lepton channel has a higher purity of Z +
jets events and therefore yields a better constraint on the normalisation. The
size of these priors as calculated by comparing \textsc{Sherpa}~2.2.1
and\textsc{MadGraph} is similar to the size as calculated by examining the
\textsc{Sherpa} internal weights.


% Secondly a parameter

% \item \textbf{ [$\textrm{CR}_{\textrm{low}}$, SR,
% $\textrm{CR}_{\textrm{high}}$] Z $p_{T}$ Migration: }: An uncertainty
% (\texttt{SysZbbPTV}) on the $Z p_{T}$ distribution (see the following section
% \ref{sec:ZPtVAndMbbShape} for details) designed to vary the final MVA fit
% discriminant in each analysis region, also alters the relative event yield
% (normalisation) between the [$\textrm{CR}_{\textrm{low}}$, SR,
% $\textrm{CR}_{\textrm{high}}$] regions. The same systematic uncertainty
% derived from the 2-lepton data-driven approach is also applied in the 0-lepton
% channel.

% \item \textbf{ [$\textrm{CR}_{\textrm{low}}$, SR,
% $\textrm{CR}_{\textrm{high}}$] Z $m_{bb}$ Migration: }: An uncertainty
% assigned to the $\textrm{CR}_{\textrm{low}}$ and $\textrm{CR}_{\textrm{high}}$
% regions as gaussian constrained nuisance parameters with priors derived
% according to Section~\ref{subsubsec:vjetsUnc}. This uncertainty allows the
% event yield in the $\textrm{CR}_{\textrm{low}}$ and
% $\textrm{CR}_{\textrm{high}}$ regions to vary relative to the SR in a
% decorrelated fashion.
% \end{itemize}

\input{07-systematic-errors/zjets-shape-yield-effect}
% The full breakdown of the migration effect induced by the \ptv\ shape
% systematic in all the analysis regions and \ptv\ bins is reported in
% Table~\ref{tab:zjets_extrapolation_uncertainties_pTVRegions} for the 2-lepton
% channel and in
% Table~\ref{tab:zjets_extrapolation_uncertainties_pTVRegions_0Lep} for the
% 0-lepton channel.\\

\subsubsection{Flavour Composition Uncertainties}

The Z + hf process breaks down in the exact same way as the W + hf process, into
$(b,b)$, $(b, c)$, $(b, l)$ and $(c, c)$ sub-components. Uncertainties on the
fraction that each of these makes up of the Z + hf process are found in
table~\ref{tab:zjets-flavour-comp}.
\input{07-systematic-errors/zjets-flavour-comp}
They are calculated using equation~\ref{eq:acceptance-dr} and applied to the
non-$(b, b)$ component of the ratio. The nuisance parameters entering into the
fit are \texttt{SysZbcZbbRatio}, \texttt{SysZccZbbRatio} and
\texttt{SysZblZbbRatio}. Priors are calculated separately in the 0-- and
2--lepton channels, and in the 2--lepton channel priors are also calculated
separately in the 2-- and 3--jet categories. The variations are nonetheless
considered to be correlated across regions. The value of the priors is
completely dominated by the difference between the nominal \textsc{Sherpa}~2.2.1
prediction and the alternative \textsc{MadGraph} prediction.

\subsubsection{Shape Uncertainties}
\input{07-systematic-errors/zjets-shape-table}
\input{07-systematic-errors/zjets-mbb-shape-plots}
\input{07-systematic-errors/zjets-ptv-shape-plots}

% The $p^{V}_{T}$ and $m_{bb}$ shape uncertainties on the $Z$+jets process are
% obtained from a data-driven method within the 2 lepton channel (where the
% $Z$+jets purity is highest). Specifically, the $e^{\pm} \mu^{\pm}$ channel is
% typically the result of either $t\bar{t}/$single top background processes or
% fake electrons/muons from miss-identified leptons/jets. Consequently, the
% $e^{\pm}\mu^{\pm}$ region is a pure top ($t\bar{t}$/single top) control region
% (TopCR), where the kinematic properties of the $t\bar{t}$/single top
% sub-processes within the TopCR region matches that of the 2-lepton
% $e^{\pm}\mu^{\pm}$ SR+CRs; details regarding this can be found in Section
% \ref{subsec:ttbar}.


% Using this Top data-driven estimate, the $p^{V}_{T}$ and $m_{bb}$
% distributions obtained according to the procedure outlined in Section
% \ref{subsec:ttbar}, are subtracted from the data within the 2-lepton SR+CRs,
% in addition to the remaining $W$+jets and $VV$ MC predictions. The $Z$+jet MC
% prediction is then scaled to the data after subtracting off the non-$Z$+jet
% backgrounds as described previously. The discrepancy between the now modified
% data $p^{V}_{T}$/$m_{bb}$ distributions and the $Z$+jets MC prediction within
% the 2-tag SR+CRs corresponds to an assessment of the systematic uncertainties
% that one can assign to the $Z$+jets background process.


% In order to account for $VH$ signal and $VZ$ contamination, the $80$ GeV
% $<m_{b\bar{b}}<140$ GeV region is removed, such that all events vetoed are
% vetoed in this window when studying the $m_{bb}$ and $p^{V}_{T}$
% distributions. %Studies pertaining to $p^{V}_{T}$ biases induced by the
% removal of the $110$ GeV $<m_{b\bar{b}}<140$ GeV region can be found in
% Appendix \ref{app:zjets}.

% The data Monte Carlo comparison inclusively of the low (75-150~GeV), medium
% (150-250~GeV), and high (> 250~GeV)) $p^{Z}_{T}$ analysis regions for
% $p^{Z}_{T}$ is shown in Figure \ref{fig:2lepptv_model} for the 2-jet, 3+ jet,
% and 2+ jet categories, whilst the $m_{b\bar{b}}$ data Monte Carlo comparison
% is shown for the low + medium + high $p^{Z}_{T}$ regions in Figure
% \ref{fig:2lepmbb_model} for the same 2-jet, 3+ jet, and 2+ jet categories.

% For the $p_T^Z$ and $m_{b\bar{b}}$ distributions the shape uncertainty is
% extracted by performing a $\chi^{2}$ functional fit in the $\geq 2$ jets
% category to the ratio of Data/MC. This category is chosen in order to maximise
% the MC and data statistics during the fit procedure thereby reducing the
% impact of statistical variance on the systematic error (2-jet and $\geq 3$ jet
% categories shown for completeness only). The shape uncertainties are indicated
% by the orange lines in the ratio of each figure, where the functional form and
% fit parameters are displayed on the top pane of each figure. The adopted shape
% systematic for the $p^{V}_{T}$ distribution has the parameteric form $y =
% -0.97.\textrm{log}_{10} (x/50000) + 1.06$, whilst for the $m_{bb}$
% distribution the parameteric form $y = 0.936 + 0.00000481x$ is used, where
% $x=\{p^{V}_{T},m_{bb}\}$ respectively.


% A summary of the $Z$+jets shape uncertainties are listed in
% Table~\ref{tab:vjetsSysSummary}, where it should be noted that the same
% parameterised uncertainties are also applied to the 0 lepton channel. With
% this in mind, it should be noted that the $m_{bb}$ observable is calculated
% using Anti-kT EMTopo $R=0.4$ jets prior to the application of the kinematic
% fit (see Ref. \cite{AlKhoury:2692011} for details), as the 0-lepton channel
% does not utilise the kinematic fit procedure.


\section{Top Quark Systematic Uncertainties}
\input{07-systematic-errors/ttbar-table.tex}

\section{Small Background Systematic Uncertainties}
\input{07-systematic-errors/small-bkg-table.tex}

\section{Signal Systematic Uncertainties}
\input{07-systematic-errors/signal-table.tex}

% \paragraph{Shape systematic Uncertainties post-processing} 

% In the current systematic model, independent normalization factors are employed
% for the main backgrounds (\ttbar, $\Wboson +$HF and $\Zboson +$HF) independently
% in $2$ and $3(+)$-jet, above or below $$p_T^V$ = 150~\GeV\$. Therefore, the
% extrapolation uncertainty is already accounted for at these boundaries. Most of
% the systematic uncertainties are computed in total $$p_T^V$$ phase space
% ($\geq75~\GeV$) in $2$-jet and $3$-jet events independently to avoid
% double-counting to the best possible. However, migrations at the $pTV=150~\GeV$
% are still possible, and differences in BDTr training and application setup or
% correlations could induce a small uncertainty componant accross jet bins. When
% visible, these effects are reduced with post-processing. The overall component
% of \ttbar ME, ttbar PS and \ttbar, $\Wboson +$HF, $\Zboson +$HF $p_T^V$
% uncertainties in the different jet bins, as well as in the bins
% $75~\GeV<$p_T^V$<150~\GeV$ and $$p_T^V$>150~\GeV$ is removed that way. \\


% Signal \mbb~shape uncertainty follow a similar but more refined treatment. In
% fact, the \VH signal is meant to have independent floating parameters in each
% STXS bin. Therefore, \VH~\mbb uncertainties are treated to have no overall
% impact in each jet and $p_T^V$ analysis bin, and act only as a shape on the
% discriminant, or as an extrapolation between signal and control regions. The
% same approach is adopted for di-boson \mbb uncertainties.

% \subsubsection{Smoothing of the Systematic Uncertainties}
% \label{sec:smooth}
% The uncertainties on reconstructed objects are propagated in the analysis in two
% different ways: by shifting weights, or by modifying the kinematic properties of
% the relevant objects and re-running the analysis chain. For flavour tagging,
% where a scale factor (SF) is used to correct efficiencies in the simulations to
% match those of data, the event weight is varied according to an upward
% (downward) shift of the SF and the change in the final distribution is noted as
% the +1 (-1) $\sigma$ uncertainties. For jet energy scale (JES) uncertainties,
% the jet energies are varied directly. Therefore events can migrate in and out of
% the analysis acceptance. Again the difference in the final discriminant is noted
% as the 1 $\sigma$ error. However, in the case of small variations and/or limited
% available MC statistics, the MC statistical uncertainty can make up a
% substantial part of this supposed systematic difference. Given that independent
% NP are introduce in the analysis to account for the MC statistical
% uncertainties, the inflation of systematic uncertainties due to limited
% statistic should be smoothed out.

% Two so-called ``smoothing'' algorithms are used to mitigate these effects. They
% have been developed for the Run 1 analysis and are based on the merging of
% consecutive bins in MC templates. Systematics templates are built as the ratios
% of varied to nominal MC templates. First, bins from one extremum to the next are
% merged until no local extrema remain in the BDT systematics template for the
% multi-variate analysis, or at most one extremum in the mbb systematics template
% for the cut-based analysis and well as the jet energy resolution systematics in
% the multi-variate analysis. This is an iterative process in which the merging
% performed at each step is chosen as the one for which the difference between
% merged and unmerged templates is smallest. Second, the bins resulting from this
% first algorithm are sequentially merged, starting from the upper end of the
% distribution, until the statistical uncertainty in each of the merged bins,
% calculated in the nominal template, is smaller than 5\%. In each of these merged
% bins, the nominal and systematically shifted contents are compared to give the
% $\pm1\sigma$ variation. This value is then used as the associated uncertainty
% for all the nominal bins in the corresponding merged bin.


% The smoothing procedure is applied to the uncertainties associated to:
% $e\gamma$, MET, muons, taus, jvt, jet, PRW and multi-jet modelling shapes. An
% example of the MET and JES systematics can be found in
% Figure~\ref{fig:Smoothing_Example}. The result of smoothing systematic
% uncertainties is checked to ensure that this is behaving as expected.

% % \begin{figure}[h]
% %   \centering
% %
%   \includegraphics[width=0.65\linewidth]{figures/stat/Smoothing/Region_BMax250_BMin150_Y6051_DSR_T2_L0_distmva_J2_VHSTXS_SysMET_SoftTrk_ResoPara.png}
% %
%   \includegraphics[width=0.65\linewidth]{figures/stat/Smoothing/Region_BMax250_BMin150_Y6051_DSR_T2_L0_distmBB_J3_VHSTXS_SysJET_CR_JET_EtaIntercalibration_Modelling.png}
% %      \caption{The variation in 0 lepton channel, 150\,\GeV$< p^{V}_{T}
% <$250\,\GeV region of the MET track-based soft term systematic in the
% multi-variate analysis (top) and the jet energy scale on eta-intercalibration
% systematic in the cut-based analysis (bottom). The dashed lines represent the
% systematic shape before smoothing and the solid lines represent the systematic
% shape after smoothing.}
% % \label{fig:Smoothing_Example}

% % \end{figure}


% \subsubsection{Pruning of the Systematic Uncertainties}
% \label{sec:smooth_prune}

% Several of the uncertainties described in Section~\ref{sec:npdefs} have a
% negligible effect on the distributions entering in the fit.  In addition,
% limited statistics in the MC nominal distributions can produce systematic
% templates with large fluctuations, introducing artificial variations in the fit.
% Therefore, following the Run 1 strategy, uncertainties are removed following a
% ``pruning'' procedure, which is carried out for each category/sub-channel in
% each region.

% Pruning is performed as follows: 
% \begin{itemize}
% \item Neglect the normalization uncertainty for a given sample in a region if either of the
%   following is true:
 
%  \begin{itemize}
%   \item the variation is less than 0.5\%
%   \item both up and down variations have the same sign
    
%  \end{itemize}

% \item Neglect the shape uncertainty for a given sample in a given region if the
%   following is true:
  
%  \begin{itemize}
%   \item not one single bin has a deviation over 0.5\% after the overall
%     normalization is removed
    
%   \item if only the up or the down variation is non-zero and passed the previous
%     pruning steps
    
%  \end{itemize}

% \item An additional pruning is made to remove systematic effects on small
%   samples in all regions. In any given region, that pruning is only applied to
%   samples contributing to less than $1\%$ of the total background and reads as
%   follow:
  
%  \begin{itemize}
%   \item in low sensitivity regions (no bin with $S/B>2\%$), normalization
%     effects below $5$ per mille of the total backgrounds and shapes varying no
%     bin by more than $5$ per mille of the total backgrounds are pruned
    
%   \item in regions where at least one bin has a signal contribution $>2\%$ of
%     the total background, shape and normalization effects are pruned if they
%     generate yield variations in these bins smaller than $2\%$ of the signal
%     yields in these bins
    
%  \end{itemize}
% \end{itemize}

% The list of pruned uncertainties is regularly checked to ensure that this is
% behaving as expected. The value of the threshold is also tested and compared to
% no-threshold for each stable iteration of the fit. This to ensure no
% over-pruning is made and the analysis sensitivity is not artificially increased.
